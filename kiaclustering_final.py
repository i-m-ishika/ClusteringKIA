# -*- coding: utf-8 -*-
"""kiaClustering_Final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Wimw3rGo1zK_Lv9EkcIRkoAoSq2cFsTD
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# uncomment for IRIS DATASET
# df=pd.read_csv("Iris.csv")


# uncomment for ECOLI DATASET
df=pd.read_csv("ecoli.csv")


#uncomment for NEW-THYROID DATASET
# df=pd.read_csv("new-thyroid.csv")
# df

# uncomment for IRIS DATASET
# data=df
# data
# del data['Id']
# species=data['Species']
# species=np.array(species)
# for i in range(data.shape[0]):
#   if species[i]=='Iris-setosa':
#     species[i]=1
#   elif species[i]=='Iris-versicolor':
#     species[i]=2
#   else:
#     species[i]=3
# del data['Species']
# print(data)



# uncomment for ECOLI DATASET
data=df
species=[]

for i in range(data.shape[0]):
  if df['Species'][i]=='cp':
    species.append(1)
  elif df['Species'][i]=='im':
    species.append(2)
  elif df['Species'][i]=='pp':
    species.append(3)
  elif df['Species'][i]=='imU':
    species.append(4)
  elif df['Species'][i]=='om':
    species.append(5)
  elif df['Species'][i]=='omL':
    species.append(6)
  elif df['Species'][i]=='imL':
    species.append(7)
  else:
    species.append(8);

species=np.array(species)
del data['Species']



#uncomment for NEW-THYROID DATASET
# data=df
# species=data['Class']

# species=np.array(species)
# for i in range(data.shape[0]):
#   if species[i]==1:
#     species[i]=1
#   elif species[i]==2:
#     species[i]=2
#   else:
#     species[i]=3
# del data['Class']

data=np.array(data)
#print(data)
#print(data.shape)

import random

def eucDistance(l1,l2):
  return sum((p-q)**2 for p,q in zip(l1,l2))**.5

def splitToCentroids(data,solute,numClusters):
  numAttr=data.shape[1]
  #divide solute into numClusters clusters, stores in array clusters
  cluster=[]
  temp = []
  for j in range(len(solute)):
    if(j%numAttr==0 and j!=0):
      cluster.append(temp)
      temp=[]
    temp.append(solute[j])
  cluster.append(temp)

  return cluster

def assignCluster(sample,numAttr,solute):
  #assigns a sample to nearest cluster
  #returns cluster number given sample is assigned to
  #solute is a list of cluster centres like [8,8,8,8,2,2,2,2,9,9,9,9] (3 clusters 4 attributes)
  #sample is a given instance of input data like [1,1,1,1] (4 attributes)
  
  cluster=[]
  cluster=splitToCentroids(data,solute,len(solute)/numAttr)

  #appropriately divides input solute into k clusters
  #example : cluster = [[8,8,8,8],[2,2,2,2],[9,9,9,9]]     

  #print(cluster)
  dist=[]
  for i in range(len(cluster)):
    dist.append(eucDistance(sample,cluster[i]))

  return dist.index(min(dist))+1
  #returns cluster number of the nearest cluster

"""assignCluster([1,2,3],3,[12,12,12,1,1,1,23,23,23])"""

def calFitness(data,solute,numClusters):
  #returns fitness value of a single solute
  #data is a numpy array
  numSamples=data.shape[0]
  numAttr=data.shape[1]
  
  assignedClusters=[]
  for i in range(numSamples):
    assignedClusters.append(assignCluster(data[i],numAttr,solute))

  #divide solute into numClusters clusters, stores in array clusters
  cluster=[]
  temp = []
  for j in range(len(solute)):
    if(j%numAttr==0 and j!=0):
      cluster.append(temp)
      temp=[]
    temp.append(solute[j])
  cluster.append(temp)

  #calculate fitness for given solute
  #as sum of distances bw each object and assigned cluster centre 

  s=0
  for i in range(numSamples):
    s=s+eucDistance(data[i],cluster[assignedClusters[i]-1])

  return s

# x=np.array([[1,2,3],[2,3,4],[81,82,84]])
# calFitness(x,[0,0,0,55,56,78,2,3,5],3)

def transformSolutes(x,pop,rand,fitness):
  #transform the solutes to new solutes
  #x is a 2d array of size pop*n where n = (no. of features) * (no. of clusters)
  #rand is a user defined number between 0 and 1 (both inclusive)
  #fitness[pop] contains fitness of all solutes

  minPos=fitness.index(min(fitness))
  sBest=[]
  sBest.append(x[minPos])
  #sBest is of the form [[1,2,3]] where [1,2,3] is the fittest solute

  xNew=[]

  for i in range(pop):
    sNew=[]
    #element wise transformation
    for j in range(len(x[i])):
      sNew.append(x[i][j]+rand*(sBest[0][j]-x[i][j]))
    xNew.append(sNew)

  return xNew

def bounds(val,lb,ub):
    if val < lb:
        val = lb
    elif val > ub:
        val = ub
    return val

def transformSolute(x,sOld,rand,fitness,lb,ub):
  #transforms a given solute to a new solute
  minPos=fitness.index(min(fitness))
  sBest=[]
  sBest.append(x[minPos])

  sNew=[]
  for i in range(len(sOld)):
    sNew.append(bounds((sOld[i]+rand*(sBest[0][i]-sOld[i])),lb,ub))


  return sNew

# x=[[1,2,3],[2,2,2],[3,4,5],[5,6,8]]
# s=[]
# s=transformSolute(x,x[3],0.4,[8,9,6])
# print(s)





# p=[[1,2,1],[1,1,1],[1,1,1]]
# p=transformSolutes([[1,2,3],[1,4,5],[4,5,6]],3,0.4,[1,9,0])
# print(p)

def calFilRate(fitness,alpha):
  #returns filtration rate
  #alpha is user defined parameter with value bw 0 and 1 (1 inclusive)
  fil=sum(fitness)/len(fitness)    
  fil=fil*alpha
  return fil

#print(calFilRate([1,2,3,6,7,97,7],0.8))

def reInit(solute,lb,ub):
  #reinitializes a given solute
  new=[]
  for i in range(len(solute)):
    r=random.uniform(lb,ub)
    new.append(r)

  return new

# x=[[1,2,3],[4,5,6],[2,2,5]]
# x[0]=reInit(x[0],3,6)
# print(x)

def calFitnessAll(data,x,pop,numClusters):
  #returns a list fitness[pop] with fitness values of all pop solutes
  #data is a numpy array
  numSamples=data.shape[0]
  numAttr=data.shape[1]
  
  fitness=[]
  #calculate fitness for each solute in x and append to fitness[]
  for i in range(pop):
    assignedClusters=[]
    for j in range(numSamples):
      assignedClusters.append(assignCluster(data[j],numAttr,x[i]))

    #divide solute into numClusters clusters, stores in array cluster
    cluster=[]
    temp = []
    for j in range(len(x[i])):
      if(j%numAttr==0 and j!=0):
        cluster.append(temp)
        temp=[]
      temp.append(x[i][j])
    cluster.append(temp)

    #calculate fitness for given solute
    #as sum of distances between each object and assigned cluster centre 

    s=0
    for i in range(numSamples):
      s=s+eucDistance(data[i],cluster[assignedClusters[i]-1])
    fitness.append(s)
    

  return fitness

# fitness=[]
# data=[[1,2,3,4,5],[1,4,7,9,10],[1,1,1,1,1]]
# data=np.array(data)
# fitness=calFitnessAll(data,[[1,3,4],[1,2,9]],2,3)
# print(fitness)

#pop population size
#mi maximum iterations
#data dataset
#k number of clusters
#m no of features in data
#rand user defined parameter used for transformation of solutes in kia

from IPython.display import clear_output
def makeClusters(pop,mi,data,k,alpha,rand):
  #makeClusters returns approximate best k clusters

  m=data.shape[1]  #number of features
  n=m*k #dimension of one solute
  x=[]  #x[pop][n] 
  
  lb=0
  ub=0  
  for i in range(pop):
     temp=np.amax(data[i],axis=0)
     if temp>ub:
      ub=temp
  # ub=ub*2

  #randomly initialize population
  for i in range(pop):
    l=[]
    for j in range(n):
      r=random.uniform(lb,ub)
      l.append(r)
    x.append(l)    

  #algorithm begins

  for i in range(mi):
    clear_output()
    print("Progress:" + str(((float(i)+1)/(mi))*100) + "%")
    
    
    #calculate fitness of each solute
    #store in fitness array
    fitness=[]
    for j in range(pop):
      fitness.append(calFitness(data,x[j],k))

    #kidney inspired algorithm
    fil=calFilRate(fitness,alpha)
    fb=[]
    w=[]
    #divide population into filtered blood and waste blood
    for i in range(pop):
      if fitness[i]<fil:
        fb.append(x[i])
      else:
        w.append(x[i])

    for i in range(pop):
      sNew=[]
      sNew=transformSolute(x,x[i],rand,fitness,lb,ub)
      f=calFitness(data,sNew,k)
      if f<fil:
        #insert sNew to FB
        fb.append(sNew)
        #move least fittest solute from FB to W
        fitnessFB=[]
        fitnessFB=calFitnessAll(data,fb,len(fb),k)
        maxPos=fitnessFB.index(max(fitnessFB))
        w.append(fb[maxPos])
        fb.pop(maxPos)

      else:
        sNew=transformSolute(x,sNew,rand,fitness,lb,ub)  
        f=calFitness(data,sNew,k)
        if f<fil:
          #insert sNew to FB
          fb.append(sNew)
          #move least fittest solute from FB to W
          fitnessFB=[]
          fitnessFB=calFitnessAll(data,fb,len(fb),k)
          maxPos=fitnessFB.index(max(fitnessFB))
          w.append(fb[maxPos])
          fb.pop(maxPos)
        else:
          #re-initialize sNew
          sNew=reInit(sNew,lb,ub)
          w.append(sNew)
    for i in range(len(fb)):
      w.append(fb[i])
    x=w


  #calculate fitness of all solutes
  fitness=[]
  fitness=calFitnessAll(data,x,pop,k)
  #solute with min fitness value
  minIndex=fitness.index(min(fitness))
  #print(fitness[minIndex])
  return x[minIndex]

clusters=[]
solute=[]
numIter =5000 #int(input("Enter number of iterations  "))
k=8 #int(input("Enter number of clusters  "))
numAttr=data.shape[1]
solute=makeClusters(50,numIter,data,k,0.5,0.5)
clusters=splitToCentroids(data,solute,3)
#print(clusters)

clusters

def sse(l1,l2):
  return sum((p-q)**2 for p,q in zip(l1,l2))
  #returns sum of squared errors



#cluster evaluation metrics

#calculate sse
assClusters=[]
for i in range(data.shape[0]):
  distance=[]
  for j in range(len(clusters)):
    distance.append(eucDistance(data[i],clusters[j]))
  assClusters.append(distance.index(min(distance))+1)
# print("Assigned Clusters: "+str(assClusters))
res_SSE=sse(species,assClusters)
# print("Standard Squared Error: "+str(res_SSE))

#Manish
clusterr=[]
#has lists of data samples belonging to clusters 1, 2, 3... k
for j in range(int(len(solute)/numAttr)):
  clusterr.append([])
for i in range(len(assClusters)):
  clusterr[int(assClusters[i]-1)].append(i)

assClusters



#Manish
from sklearn.metrics import davies_bouldin_score
#print("DBIndex:"+str(davies_bouldin_score(data, assClusters)))
from sklearn import metrics
#print("SilhouetteIndex:"+str(metrics.silhouette_score(data, assClusters, metric='euclidean')))

#calculate accuracy
acc=0
for i in range(len(species)):
  if species[i]==assClusters[i]:
    acc=acc+1

acc=(acc/data.shape[0])*100
# print(acc)

import csv
#write cluster centres to a csv file
str1='result'+str(numIter)+'.csv'
with open(str1,'w',newline='') as file:
  writer=csv.writer(file)
  writer.writerow([" Data Index","Assigned Cluster"])
  for i in range(len(assClusters)):
    writer.writerow([i+1,assClusters[i]])

  writer.writerow(["Accuracy : ",acc])
  writer.writerow(["SSE : ",res_SSE])



"""
from mpl_toolkits.mplot3d import Axes3D
import matplotlib.pyplot as plt
import numpy as np
n=150
fig = plt.figure()
ax = fig.add_subplot(111,projection='3d')
temp = []
for i in range(n):
  temp.append(data[i][0])
xx = temp
temp = []
for i in range(n):
  temp.append(data[i][1])
y = temp
temp = []
for i in range(n):
  temp.append(data[i][2])
z = temp
temp = []
for i in range(n):
  temp.append(data[i][3])
c = temp
n=3
img = ax.scatter(xx, y, z, c=c, cmap=plt.hot(), marker='+')
# ax = fig.add_subplot(111,projection='3d')
temp = []
for i in range(n):
  temp.append(clusters[i][0])
xx = temp
temp = []
for i in range(n):
  temp.append(clusters[i][1])
y = temp
temp = []
for i in range(n):
  temp.append(clusters[i][2])
z = temp
temp = []
for i in range(n):
  temp.append(clusters[i][3])
c = temp

img = ax.scatter(xx, y, z, color='#0000FF')
fig.colorbar(img)
plt.show()
"""

#assClusters

#Manish
import math
def find_cosine(cluster_cent,cluster,k,data,no_of_attr):
    c_sum=[]
    for i in range(k):
        c=0
        for j in cluster[i]:
            z=0
            x=0
            y=0
            for o in range(no_of_attr):
                z=z+(cluster_cent[i][o]*data.iloc[j][o])
                y=y+(cluster_cent[i][o])**2
                x=x+(data.iloc[j][o])**2
            y=math.sqrt(y)
            x=math.sqrt(x)
            z=z/(y*x)
            c=c+z
            
        c_sum.append(c)
    return c_sum



#calculate g
def calc_g(cos,k,cluster):
    g=[]
    for i in range(k):
        if(len(cluster[i])!=0):
          m=((0.5*(len(cluster[i])))+(cos[i]/2))/(len(cluster[i]))
        else:
          m=1
        g.append(m)
    return g

#calculate h for each cluster
def calc_h(g):
    h=[]
    for i in range(len(g)):
        if g[i]==1:
          g[i]=g[i]-0.001
        m=(g[i]*math.log2(g[i])) + ((1-g[i])*math.log2(1-g[i]))*(-1)
        h.append(m)
    
    return h


def final_entropy(h,g):
    s=0
    for i in range(len(g)):
        s=s + math.sqrt(1-(h[i]*g[i]))
        
    return s


temp1=[]
temp2=[]
for i in range(len(clusterr)):
  if(len(clusterr[i])!=0):
    temp1.append(clusters[i])
    temp2.append(clusterr[i])







cos=find_cosine(temp1,temp2,len(temp2),pd.DataFrame.from_records(data),numAttr)    
g=calc_g(cos,len(temp2),temp2)
h=calc_h(g)
H=final_entropy(h,g)


#print(H)

with open(str1,'a',newline='') as file:
  writer=csv.writer(file)
  writer.writerow(["Entropy : ",H])
  writer.writerow(["DBIndex:",(davies_bouldin_score(data, assClusters))])
  writer.writerow(["SilhouetteIndex:",(metrics.silhouette_score(data, assClusters, metric='euclidean'))])



